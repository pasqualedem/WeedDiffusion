{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e323589d",
   "metadata": {},
   "source": [
    "**INPAINTING-BASED AUGMENTATION FOR CROPS**\n",
    "\n",
    "This script performs inpainting-based data augmentation by inserting new crop instances into existing field images using a Stable Diffusion model fine-tuned via DreamBooth.\n",
    "\n",
    "After training a custom model (model_crops) to learn the visual appearance of a specific crop (e.g., sugar beet), this script uses inpainting to:\n",
    "- Mask part of an input image (left or right portion).\n",
    "- Prompt the model to fill in the masked area with new, realistic crops.\n",
    "- Generate augmented training samples with richer crop diversity and spatial configurations.\n",
    "\n",
    "This method is only applied to crop augmentation, not to weeds, and is crucial for enriching the dataset with synthetic but coherent variations of crops class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2935369b",
   "metadata": {},
   "source": [
    "*Library Imports and Initial Setup*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cb9a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from diffusers import StableDiffusionInpaintPipeline\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_dir = \"images_to_modify\"\n",
    "prompt = \"sks crop\"\n",
    "output_dir = \"inpainting_outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "pipe = StableDiffusionInpaintPipeline.from_pretrained(\n",
    "    \"models/model_crops\",\n",
    "    torch_dtype=torch.float16\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c8f728",
   "metadata": {},
   "source": [
    "This function creates a binary mask (also called an overlay) that defines the region of the image to be inpainted.\n",
    "Depending on the specified width_fraction and direction, it masks a portion of the image on the left or right side, allowing the model to insert new crop instances in that area.\n",
    "\n",
    "The resulting mask is used as input for the inpainting pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82001f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_overlay(image, width_fraction=0.3, direction='right'):\n",
    "    width, height = image.size\n",
    "    overlay = Image.new(\"L\", (width, height), 0)\n",
    "    start_x = int(width * (1 - width_fraction)) if direction == 'right' else 0\n",
    "    end_x = width if direction == 'right' else int(width_fraction * width)\n",
    "\n",
    "    for x in range(start_x, end_x):\n",
    "        for y in range(height):\n",
    "            overlay.putpixel((x, y), 255)\n",
    "\n",
    "    return overlay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d984ba5",
   "metadata": {},
   "source": [
    "This function runs the inpainting process using the fine-tuned Stable Diffusion pipeline.\n",
    "\n",
    "Key settings:\n",
    "- prompt: guides the content to be generated in the masked area (e.g., \"sks crop\").\n",
    "- overlay: the binary mask indicating where new content should be generated.\n",
    "- height and width are both set to 1024 to match the resolution of the original dataset images.\n",
    "- guidance_scale = 7.5: controls how strongly the generation is influenced by the prompt.\n",
    "- num_inference_steps = 300: ensures high-quality and detailed inpainted results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ffcd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inpainting(image, overlay, prompt, out_path):\n",
    "    result = pipe(\n",
    "        prompt=prompt,\n",
    "        image=image,\n",
    "        mask_image=overlay,\n",
    "        guidance_scale=7.5,\n",
    "        num_inference_steps=300,\n",
    "        height=1024,\n",
    "        width=1024\n",
    "    ).images[0]\n",
    "    result.save(out_path)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb79d9c",
   "metadata": {},
   "source": [
    "This section loops over all images in the images_to_modify/ directory and applies inpainting-based augmentation using different mask configurations.\n",
    "- For each image, multiple masks are generated by varying the width (20â€“30-40%) and side (left or right).\n",
    "- The fine-tuned model fills the masked region with new crop instances based on the prompt (\"sks crop\").\n",
    "- Each output is saved with a suffix indicating the mask parameters, e.g., image_left_30.png.\n",
    "\n",
    "The function *visualize_result(...)* displays:\n",
    "- The original image.\n",
    "- The image with the masked area highlighted in red.\n",
    "- The inpainted result, showing newly generated crops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da54743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_result(original, overlay, inpainted, title):\n",
    "    red_overlay = np.array(original).copy()\n",
    "    overlay_np = np.array(overlay.resize(original.size))\n",
    "    red_overlay[overlay_np > 0] = [255, 0, 0]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    axes[0].imshow(original)\n",
    "    axes[0].set_title(\"Original Image\")\n",
    "    axes[1].imshow(red_overlay)\n",
    "    axes[1].set_title(\"overlay Overlay\")\n",
    "    axes[2].imshow(inpainted)\n",
    "    axes[2].set_title(f\"Inpainting: {title}\")\n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "fractions = [0.2, 0.3, 0.4]\n",
    "directions = ['left', 'right']\n",
    "image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "for img_name in image_files:\n",
    "    img_path = os.path.join(image_dir, img_name)\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    base_name = os.path.splitext(img_name)[0]\n",
    "\n",
    "    for direction in directions:\n",
    "        for frac in fractions:\n",
    "            overlay = generate_overlay(image, width_fraction=frac, direction=direction)\n",
    "            suffix = f\"{direction}_{int(frac * 100)}\"\n",
    "            out_name = f\"{base_name}_{suffix}.png\"\n",
    "            out_path = os.path.join(output_dir, out_name)\n",
    "\n",
    "            print(f\"Processing {img_name} | {suffix}\")\n",
    "            result = run_inpainting(image, overlay, prompt, out_path)\n",
    "            visualize_result(image, overlay, result, suffix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
